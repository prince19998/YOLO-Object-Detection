{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # objection detection and recording and saving\n",
    "\n",
    "# import cv2\n",
    "# import datetime\n",
    "# from ultralytics import YOLO  # For YOLOv8, install with `pip install ultralytics`\n",
    "# from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "# # Load YOLO model\n",
    "# # model = YOLO(\"yolov8n.pt\")  # Replace with your model file path\n",
    "# model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "\n",
    "# # Initialize webcam\n",
    "# cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras\n",
    "\n",
    "# # Get video properties\n",
    "# frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "# # Create VideoWriter with date-time-stamped filename\n",
    "# date_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# output_file = f\"output_{date_time}.mp4\"\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "# out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"Recording started: {output_file}\")\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "#             break\n",
    "\n",
    "#         annotator = Annotator(frame, line_width=2) #  Initialize Annotator\n",
    "\n",
    "#         # Perform object detection\n",
    "#         results = model.predict(frame, conf=0.5)  # Adjust confidence threshold\n",
    "#         annotated_frame = results[0].plot()  # Annotated frame\n",
    "        \n",
    "#         results = model.track(frame, conf=0.5,tracker=\"bytetrack.yaml\")  # Adjust confidence threshold\n",
    "#         annotated_frame = results[0].plot() \n",
    "        \n",
    "\n",
    "#         # Show the frame with detections\n",
    "#         cv2.imshow(\"YOLO Object Detection and Tracking\", annotated_frame)\n",
    "\n",
    "#         # Write the frame to the output file\n",
    "#         out.write(annotated_frame)\n",
    "        \n",
    "\n",
    "#         # Press 'q' to quit\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# finally:\n",
    "#     # Release resources\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     print(f\"Recording saved asq {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import datetime\n",
    "# import os\n",
    "# import mysql.connector\n",
    "# from ultralytics import YOLO  # For YOLOv8, install with `pip install ultralytics`\n",
    "# from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "# # MySQL Database Configuration\n",
    "# db_config = {\n",
    "#     'host': 'localhost',\n",
    "#     'user': 'root',        # Replace with your MySQL username\n",
    "#     'password': '6386664148',    # Replace with your MySQL password\n",
    "#     'database': 'terminal_output_db', # Replace with your database name\n",
    "#     'port' : '3306'\n",
    "# }\n",
    "\n",
    "# # Connect to MySQL\n",
    "# db_conn = mysql.connector.connect(**db_config)\n",
    "# cursor = db_conn.cursor()\n",
    "\n",
    "# # Load YOLO model\n",
    "# model = YOLO(\"yolo11n.pt\")  # Replace with your model file path\n",
    "\n",
    "# # Initialize webcam\n",
    "# cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras\n",
    "\n",
    "# # Get video properties\n",
    "# frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "# # Create VideoWriter with date-time-stamped filename\n",
    "# date_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# output_file = f\"output_{date_time}.mp4\"\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "# out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# # Directory to save detected images\n",
    "# save_dir = \"detected_images\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# print(f\"Recording started: {output_file}\")\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             log_message = \"Video frame is empty or video processing has been successfully completed.\"\n",
    "#             print(log_message)\n",
    "#             cursor.execute(\"INSERT INTO detection_log (timestamp, log_message) VALUES (%s, %s)\", \n",
    "#                            (datetime.datetime.now(), log_message))\n",
    "#             db_conn.commit()\n",
    "#             break\n",
    "\n",
    "#         # Perform object detection\n",
    "#         results = model.predict(frame, conf=0.5)  # Adjust confidence threshold\n",
    "#         boxes = results[0].boxes  # Get bounding boxes\n",
    "\n",
    "#         # Only proceed if objects are detected\n",
    "#         if len(boxes) > 0:\n",
    "#             # Annotate detected objects on the frame\n",
    "#             annotated_frame = results[0].plot()  # Annotated frame\n",
    "\n",
    "#             # Save the frame as an image with a timestamp\n",
    "#             timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "#             image_filename = f\"{save_dir}/detected_{timestamp}.jpg\"\n",
    "#             cv2.imwrite(image_filename, frame)  # Save the frame as an image\n",
    "#             log_message = f\"Image saved: {image_filename}\"\n",
    "#             print(log_message)\n",
    "\n",
    "#             # Log detection in MySQL\n",
    "#             cursor.execute(\"INSERT INTO detection_log (timestamp, log_message) VALUES (%s, %s)\", \n",
    "#                            (datetime.datetime.now(), log_message))\n",
    "#             db_conn.commit()\n",
    "\n",
    "#             # Write the annotated frame to the video output\n",
    "#             out.write(annotated_frame)\n",
    "\n",
    "#             # Display the annotated frame\n",
    "#             cv2.imshow(\"YOLO Object Detection\", annotated_frame)\n",
    "#         else:\n",
    "#             # If no objects are detected, display the original frame\n",
    "#             cv2.imshow(\"YOLO Object Detection\", frame)\n",
    "\n",
    "#         # Press 'q' to quit\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# finally:\n",
    "#     # Release resources\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     db_conn.close()\n",
    "#     print(f\"Recording saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATABASE terminal_output_db;\n",
    "\n",
    "# USE terminal_output_db;\n",
    "\n",
    "# CREATE TABLE detection_log (\n",
    "#     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#     timestamp DATETIME NOT NULL,\n",
    "#     log_message TEXT NOT NULL\n",
    "# );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started: output_2024-12-03_15-14-36.mp4\n",
      "\n",
      "0: 480x640 1 person, 1019.7ms\n",
      "Speed: 10.7ms preprocess, 1019.7ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-41-195207.jpg\n",
      "Detection saved to database: person (0.71)\n",
      "\n",
      "0: 480x640 1 person, 1894.1ms\n",
      "Speed: 67.0ms preprocess, 1894.1ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-43-388996.jpg\n",
      "Detection saved to database: person (0.64)\n",
      "\n",
      "0: 480x640 (no detections), 1115.1ms\n",
      "Speed: 95.3ms preprocess, 1115.1ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1155.6ms\n",
      "Speed: 28.5ms preprocess, 1155.6ms inference, 20.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-45-959479.jpg\n",
      "Detection saved to database: person (0.53)\n",
      "\n",
      "0: 480x640 1 person, 1116.8ms\n",
      "Speed: 37.7ms preprocess, 1116.8ms inference, 21.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-47-275456.jpg\n",
      "Detection saved to database: person (0.77)\n",
      "\n",
      "0: 480x640 (no detections), 1028.7ms\n",
      "Speed: 20.4ms preprocess, 1028.7ms inference, 13.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1127.3ms\n",
      "Speed: 10.4ms preprocess, 1127.3ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-49-622982.jpg\n",
      "Detection saved to database: person (0.58)\n",
      "\n",
      "0: 480x640 1 person, 1045.6ms\n",
      "Speed: 8.4ms preprocess, 1045.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-50-774953.jpg\n",
      "Detection saved to database: person (0.53)\n",
      "\n",
      "0: 480x640 1 person, 901.2ms\n",
      "Speed: 18.6ms preprocess, 901.2ms inference, 10.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-51-794806.jpg\n",
      "Detection saved to database: person (0.87)\n",
      "\n",
      "0: 480x640 (no detections), 895.4ms\n",
      "Speed: 10.3ms preprocess, 895.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 852.1ms\n",
      "Speed: 16.7ms preprocess, 852.1ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-53-701784.jpg\n",
      "Detection saved to database: person (0.81)\n",
      "\n",
      "0: 480x640 1 person, 858.1ms\n",
      "Speed: 10.4ms preprocess, 858.1ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-54-666755.jpg\n",
      "Detection saved to database: person (0.55)\n",
      "\n",
      "0: 480x640 1 person, 895.1ms\n",
      "Speed: 10.9ms preprocess, 895.1ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-55-670016.jpg\n",
      "Detection saved to database: person (0.64)\n",
      "\n",
      "0: 480x640 (no detections), 866.8ms\n",
      "Speed: 10.3ms preprocess, 866.8ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 keyboard, 881.7ms\n",
      "Speed: 16.7ms preprocess, 881.7ms inference, 18.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-57-608140.jpg\n",
      "Detection saved to database: person (0.79)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-57-658860.jpg\n",
      "Detection saved to database: keyboard (0.54)\n",
      "\n",
      "0: 480x640 1 person, 932.8ms\n",
      "Speed: 10.4ms preprocess, 932.8ms inference, 20.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-58-699728.jpg\n",
      "Detection saved to database: person (0.63)\n",
      "\n",
      "0: 480x640 1 person, 987.9ms\n",
      "Speed: 13.7ms preprocess, 987.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-14-59-807051.jpg\n",
      "Detection saved to database: person (0.74)\n",
      "\n",
      "0: 480x640 1 person, 929.0ms\n",
      "Speed: 18.5ms preprocess, 929.0ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-00-853300.jpg\n",
      "Detection saved to database: person (0.68)\n",
      "\n",
      "0: 480x640 1 person, 916.8ms\n",
      "Speed: 13.7ms preprocess, 916.8ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-01-895494.jpg\n",
      "Detection saved to database: person (0.85)\n",
      "\n",
      "0: 480x640 1 person, 1384.3ms\n",
      "Speed: 12.4ms preprocess, 1384.3ms inference, 18.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-03-412554.jpg\n",
      "Detection saved to database: person (0.85)\n",
      "\n",
      "0: 480x640 1 person, 3112.2ms\n",
      "Speed: 164.0ms preprocess, 3112.2ms inference, 18.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-06-938512.jpg\n",
      "Detection saved to database: person (0.82)\n",
      "\n",
      "0: 480x640 (no detections), 889.3ms\n",
      "Speed: 10.2ms preprocess, 889.3ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 974.1ms\n",
      "Speed: 13.0ms preprocess, 974.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-08-956864.jpg\n",
      "Detection saved to database: person (0.83)\n",
      "\n",
      "0: 480x640 1 person, 1519.1ms\n",
      "Speed: 15.7ms preprocess, 1519.1ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-10-617773.jpg\n",
      "Detection saved to database: person (0.84)\n",
      "\n",
      "0: 480x640 1 person, 937.1ms\n",
      "Speed: 7.6ms preprocess, 937.1ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-11-676738.jpg\n",
      "Detection saved to database: person (0.66)\n",
      "\n",
      "0: 480x640 1 person, 840.8ms\n",
      "Speed: 7.5ms preprocess, 840.8ms inference, 8.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-12-628486.jpg\n",
      "Detection saved to database: person (0.81)\n",
      "\n",
      "0: 480x640 1 person, 893.2ms\n",
      "Speed: 10.2ms preprocess, 893.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-13-636786.jpg\n",
      "Detection saved to database: person (0.62)\n",
      "\n",
      "0: 480x640 (no detections), 936.8ms\n",
      "Speed: 10.3ms preprocess, 936.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 928.3ms\n",
      "Speed: 7.5ms preprocess, 928.3ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 944.9ms\n",
      "Speed: 25.5ms preprocess, 944.9ms inference, 41.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-16-710441.jpg\n",
      "Detection saved to database: person (0.81)\n",
      "\n",
      "0: 480x640 1 person, 1514.0ms\n",
      "Speed: 104.3ms preprocess, 1514.0ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-18-869149.jpg\n",
      "Detection saved to database: person (0.71)\n",
      "\n",
      "0: 480x640 1 person, 1258.2ms\n",
      "Speed: 12.6ms preprocess, 1258.2ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-20-242757.jpg\n",
      "Detection saved to database: person (0.53)\n",
      "\n",
      "0: 480x640 1 person, 885.2ms\n",
      "Speed: 6.8ms preprocess, 885.2ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-21-271348.jpg\n",
      "Detection saved to database: person (0.66)\n",
      "\n",
      "0: 480x640 (no detections), 912.0ms\n",
      "Speed: 12.5ms preprocess, 912.0ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 838.3ms\n",
      "Speed: 13.5ms preprocess, 838.3ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-23-183574.jpg\n",
      "Detection saved to database: person (0.56)\n",
      "\n",
      "0: 480x640 1 person, 828.3ms\n",
      "Speed: 10.5ms preprocess, 828.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-24-131935.jpg\n",
      "Detection saved to database: person (0.54)\n",
      "\n",
      "0: 480x640 2 persons, 831.0ms\n",
      "Speed: 14.9ms preprocess, 831.0ms inference, 10.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-25-077755.jpg\n",
      "Detection saved to database: person (0.56)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-25-129097.jpg\n",
      "Detection saved to database: person (0.56)\n",
      "\n",
      "0: 480x640 1 person, 836.6ms\n",
      "Speed: 10.1ms preprocess, 836.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-26-064122.jpg\n",
      "Detection saved to database: person (0.75)\n",
      "\n",
      "0: 480x640 2 persons, 844.1ms\n",
      "Speed: 5.3ms preprocess, 844.1ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-27-010168.jpg\n",
      "Detection saved to database: person (0.62)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-27-072559.jpg\n",
      "Detection saved to database: person (0.52)\n",
      "\n",
      "0: 480x640 1 person, 1240.7ms\n",
      "Speed: 12.3ms preprocess, 1240.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-28-406582.jpg\n",
      "Detection saved to database: person (0.51)\n",
      "\n",
      "0: 480x640 2 persons, 871.3ms\n",
      "Speed: 15.3ms preprocess, 871.3ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-29-410014.jpg\n",
      "Detection saved to database: person (0.73)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-29-483237.jpg\n",
      "Detection saved to database: person (0.50)\n",
      "\n",
      "0: 480x640 (no detections), 1057.3ms\n",
      "Speed: 13.7ms preprocess, 1057.3ms inference, 13.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 998.8ms\n",
      "Speed: 50.7ms preprocess, 998.8ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1007.5ms\n",
      "Speed: 121.5ms preprocess, 1007.5ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1918.3ms\n",
      "Speed: 44.7ms preprocess, 1918.3ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 1046.1ms\n",
      "Speed: 24.6ms preprocess, 1046.1ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 927.1ms\n",
      "Speed: 106.1ms preprocess, 927.1ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Image saved: detected_images/detected_2024-12-03_15-15-37-162555.jpg\n",
      "Detection saved to database: person (0.67)\n",
      "Recording saved as output_2024-12-03_15-14-36.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import mysql.connector\n",
    "from ultralytics import YOLO  # For YOLOv8, install with `pip install ultralytics`\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolo11n.pt\")  # Replace with your model file path\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # Change index if you have multiple cameras\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "# Create VideoWriter with date-time-stamped filename\n",
    "date_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_file = f\"output_{date_time}.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Directory to save detected images\n",
    "save_dir = \"detected_images\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Connect to MySQL database\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"Your_User\",       # Replace with your MySQL username\n",
    "    password=\"Your_Password\",   # Replace with your MySQL password\n",
    "    database=\"yolo_detection\",  # Ensure the database exists\n",
    "    port=\"Your_Port\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "print(f\"Recording started: {output_file}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "\n",
    "        # Perform object detection\n",
    "        results = model.predict(frame, conf=0.5)  # Adjust confidence threshold\n",
    "        boxes = results[0].boxes  # Get bounding boxes\n",
    "\n",
    "        # Only proceed if objects are detected\n",
    "        if len(boxes) > 0:\n",
    "            # Annotate detected objects on the frame\n",
    "            annotated_frame = results[0].plot()  # Annotated frame\n",
    "\n",
    "            \n",
    "            for box in boxes:\n",
    "                class_name = model.names[int(box.cls)]  # Get class name\n",
    "                confidence = float(box.conf)  # Confidence score\n",
    "\n",
    "                # Save the frame as an image with a timestamp\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Corrected timestamp format\n",
    "                image_filename = f\"{save_dir}/detected_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S-%f')}.jpg\"\n",
    "                cv2.imwrite(image_filename, frame)  # Save the frame as an image\n",
    "                print(f\"Image saved: {image_filename}\")\n",
    "\n",
    "                # Insert detection data into the database\n",
    "                insert_query = \"\"\"\n",
    "                INSERT INTO detections (timestamp, detected_class, confidence, image_path)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                cursor.execute(insert_query, (timestamp, class_name, confidence, image_filename))\n",
    "                db.commit()\n",
    "                print(f\"Detection saved to database: {class_name} ({confidence:.2f})\")\n",
    "\n",
    "\n",
    "            # Write the annotated frame to the video output\n",
    "            out.write(annotated_frame)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"YOLO Object Detection And Tracking\", annotated_frame)\n",
    "        else:\n",
    "            # If no objects are detected, display the original frame\n",
    "            cv2.imshow(\"YOLO Object Detection And Tracking\", frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    print(f\"Recording saved as {output_file}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
